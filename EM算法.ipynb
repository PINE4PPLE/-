{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EM算法\n",
    "## EM算法\n",
    "EM算法是含有隐变量的概率模型参数的极大似然估计法。\n",
    "**EM算法**\n",
    "输入：观测变量数据Y，隐变量数据Z，联合分布P(Y,Z|$\\theta$)，条件分布P(Z|Y，$\\theta$);\n",
    "\n",
    "输出：模型参数$\\theta$\n",
    "\n",
    "(1)选择初值$\\theta^{(0)}$;\n",
    "\n",
    "(2)E步：记$\\theta^{(i)}$为第i次迭代参数$\\theta$的值，在第i+1次迭代的E步，计算\n",
    "$$\n",
    "Q(\\theta,\\theta^{(i)})=E_{Z}[logP(Y,Z|\\theta)|Y,\\theta^{(i)}]\\\\\n",
    "=\\sum_ZlogP(Y,Z|\\theta)P(Z|Y,\\theta)\n",
    "$$\n",
    "\n",
    "(3)M步求使$Q(\\theta,\\theta^{(i)})$极大化的$\\theta$。\n",
    "$$\n",
    "\\theta^{(i+1)}=arg\\max_{\\theta}Q(\\theta,\\theta^{(i)})\n",
    "$$\n",
    "\n",
    "(4)重复(2)(3)直至收敛。\n",
    "## 算法收敛性证明\n",
    "要证明算法收敛，即需要证明$P(Y|\\theta^{(i+1)})\\ge P(Y|\\theta^{(i)})$\n",
    "$$\n",
    "P(Y,Z|\\theta)=P(Z|Y,\\theta)*P(Y|\\theta)\\\\\n",
    "logP(Y|\\theta) = logP(Y,Z|\\theta) - logP(Z|Y,\\theta)\\\\\n",
    "$$\n",
    "两侧同时乘$P(Z|Y,\\theta^{(i)})$,求积分得\n",
    "$$\n",
    "left = \\int_ZlogP(Y|\\theta)P(Z|Y,\\theta^{(i)})dz\\\\\n",
    "=logP(Y|\\theta)\\int_ZP(Z|Y,\\theta^{(i)})\\\\\n",
    "=logP(Y|\\theta)\n",
    "$$\n",
    "$$\n",
    "right = \\int_ZlogP(Y,Z|\\theta)P(Z|Y,\\theta^{(i)})dz - \\int_ZlogP(Z|Y,\\theta)P(Z|Y,\\theta^{(i)})dz\\\\\n",
    "=Q(\\theta,\\theta^{(i)})-H(\\theta,\\theta^{(i)})\n",
    "$$\n",
    "由$\\theta$的迭代方式可得，$Q(\\theta^{(i)},\\theta^{(i)})\\le Q(\\theta^{(i+1)},\\theta^{(i)})$\n",
    "$$\n",
    "H(\\theta^{(i+1)},\\theta^{(i)})-H(\\theta^{(i)},\\theta^{(i)})\\\\\n",
    "=\\int_ZP(Z|Y,\\theta^{(i)})\\frac{logP(Z|Y,\\theta^{(i+1)})}{logP(Z|Y,\\theta^{(i)})}dz\\\\\n",
    "=-KL(P(Z|Y,\\theta^{(i)})||P(Z|Y,\\theta^{(i+1)}))\\le 0\n",
    "$$\n",
    "因此，可得$P(Y|\\theta^{(i+1)})\\ge P(Y|\\theta^{(i)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法公式导出\n",
    "### ELBO+KL divergence\n",
    "$$\n",
    "logP(Y|\\theta) = log\\frac{P(Y,Z|\\theta)}{q(Z)} - log\\frac{P(Z|Y,\\theta)}{q(Z)}\n",
    "$$\n",
    "在两边同时乘$q(Z)$并积分得\n",
    "$$\n",
    "logP(Y|\\theta) = \\int_Zq(Z)log\\frac{P(Y,Z|\\theta)}{q(Z)}dz - \\int_Zq(Z)log\\frac{P(Z|Y,\\theta)}{q(Z)}dz\\\\\n",
    "=ELBO+KL(q(Z)||P(z|Y,\\theta))\n",
    "$$\n",
    "可得$logP(X|\\theta)\\ge ELBO$\n",
    "### ELBO+jesen's inequality\n",
    "$$\n",
    "logP(Y|\\theta)=log\\int_ZP(Y,Z|\\theta)dz\\\\\n",
    "=log\\int_Z\\frac{P(Y,Z|\\theta)}{q(Z)}q(Z)dz\\\\\n",
    "=logE_{q(Z)}[\\frac{P(Y,Z|\\theta)}{q(Z)}]\n",
    "$$\n",
    "同时由jesen不等式得,对于凸函数f,$\\lambda\\in[0,1]$,\n",
    "$$\n",
    "f(\\lambda x_1+ (1-\\lambda)x_2)\\ge \\lambda f(x_1)+(1-\\lambda)f(x_2)\n",
    "$$\n",
    "推理得对凸函数f，\n",
    "$$\n",
    "f(E(X))\\ge E(f(X))\n",
    "$$\n",
    "因此可以得出\n",
    "$$\n",
    "logP(Y|\\theta)\\ge E_{q(Z)}(log(\\frac{P(Y,Z|\\theta)}{q(Z)}))\n",
    "$$\n",
    "且“=”成立当且仅当$\\frac{P(Y,Z|\\theta)}{q(Z)}=c$,其中c为常数。\n",
    "\n",
    "则$q(Z)=\\frac{1}{c}P(Y,Z|\\theta)$,对两边求积分得\n",
    "$$\n",
    "1 = \\frac{1}{c}\\int_ZP(Y,Z|\\theta)dz\n",
    "$$\n",
    "可得$c = P(Y|\\theta)$,即$q(Z) = \\frac{P(Y,Z|\\theta)}{P(Y|\\theta)}=P(Z|Y,\\theta)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 广义EM算法\n",
    "由上文可知，引入概率分布q（Z），$logP(Y|\\theta) = ELBO + KL(q||p)$\n",
    "$ELBO = L(q,\\theta) = E_{q(Z)}(logP(Y,Z|\\theta) - logq(Z))$\n",
    "\n",
    "可得$ELBO = E_q[logP(y,z|\\theta)] - H(q)$,其中H（q）为q分布的熵。\n",
    "\n",
    "广义EM算法中的E步和M步为两个极大\n",
    "$$\n",
    "E-step: q^{(i+1)} = arg\\max_qL(q,\\theta^{(t)})\\\\\n",
    "M-step: \\theta^{(i+1)} = arg\\max_{\\theta}L(q^{(t)},\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EM算法在高斯混合模型学习中的应用\n",
    "### 高斯混合模型\n",
    "**高斯混合模型**是指具有如下形式的概率分布模型：\n",
    "$$\n",
    "P(y|\\theta)=\\sum_{k=1}^K\\alpha_k\\phi(y|\\theta_k)\n",
    "$$\n",
    "其中，$\\alpha_k$为系数，$\\sum_{k=1}^K\\alpha_k=1$,$\\phi(y|\\theta_k)$为高斯分布密度，$\\theta_k=(\\mu_k,\\sigma_k^2)$\n",
    "### EM算法\n",
    "输入：观测数据$y_1,y_2,\\cdots,y_N$,高斯混合模型；\n",
    "\n",
    "输出：高斯混合模型参数\n",
    "\n",
    "(1)取参数初值开始迭代。\n",
    "\n",
    "(2)E步：依据当前模型参数，计算分分模型k对观测数据$y_j$的响应度。\n",
    "$$\n",
    "\\hat{\\gamma_k}=\\frac{\\alpha_k\\phi(y_j|\\theta_k)}{\\sum_{k=1}^K\\alpha_k\\phi(y_j|\\theta_k)}\n",
    "$$\n",
    "\n",
    "(3)M步：计算新一轮迭代的模型参数。\n",
    "$$\n",
    "\\hat{\\mu_k}=\\frac{\\sum_{j=1}^N\\hat{\\gamma_{jk}}y_j}{\\sum_{j=1}^N\\hat{\\gamma_{jk}}}\\\\\n",
    "\\hat{\\sigma_k}=\\frac{\\sum_{j=1}^N\\hat{\\gamma_{jk}}(y_j-\\mu_k)^2}{\\sum_{j=1}^N\\hat{\\gamma_{jk}}}\\\\\n",
    "\\hat{\\alpha_k}=\\frac{\\sum_{j=1}^N\\hat{\\gamma_{jk}}}{N}\n",
    "$$\n",
    "\n",
    "(4)重复2，3步直至收敛。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
