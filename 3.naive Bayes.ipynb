{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯\n",
    "## 朴素贝叶斯法的学习与分类\n",
    "### 基本方法\n",
    "训练数据集$T=\\{(x_1,y_1),(x_1,y_1),\\cdots ,(x_N,y_N)\\}$由X和Y的联合概率分布*P*(X,Y)独立同分布产生。\n",
    "朴素贝叶斯对条件概率分布做了条件独立性假设，即\n",
    "$$\n",
    "P(X=x|Y=c_k)=P(X^{(1)}=x^{(1)},X^{(2)}=x^{(2)},\\cdots,X^{(n)}=x^{(n)}|Y=c_k)\\\\\n",
    "=\\prod^n_{j=1}P(X^{(j)}=x^{(j)}|Y=c_k)\n",
    "$$\n",
    "朴素贝叶斯法实际上学习到生成数据的机制，所以属于生成模型。\n",
    "朴素贝叶斯进行分类时，对于给定输入x，通过学习到的模型计算后验概率分布$P(Y=c_k|X=x)$，将后验概率最大的类作为x的类输出。\n",
    "$$\n",
    "P(Y=c_k|X=x)=\\frac{P(X=x|Y=c_k)P(Y=c_k)}{P(X=x)}\\\\\n",
    "=\\frac{P(X=x|Y=c_k)P(Y=c_k)}{\\sum_kP(X=x|Y=c_k)P(Y=c_k)}\\\\\n",
    "=\\frac{P(Y=c_k)\\prod^n_{j=1}P(X^{(j)}=x^{(j)}|Y=c_k)}{\\sum_kP(Y=c_k)\\prod^n_{j=1}P(X^{(j)}=x^{(j)}|Y=c_k)}\n",
    "$$\n",
    "于是，朴素贝叶斯分类器可以表示为\n",
    "$$\n",
    "y=f(x)=\\operatorname{arg}\\max_{c_k}\\frac{P(Y=c_k)\\prod^n_{j=1}P(X^{(j)}=x^{(j)}|Y=c_k)}{\\sum_kP(Y=c_k)\\prod^n_{j=1}P(X^{(j)}=x^{(j)}|Y=c_k)}\n",
    "$$\n",
    "注意到，上式中对所有$c_k$,分母都是相同的，所以可以得到\n",
    "$$\n",
    "y=f(x)=\\operatorname{arg}\\max_{c_k}P(Y=c_k)\\prod^n_{j=1}P(X^{(j)}=x^{(j)}|Y=c_k)\n",
    "$$\n",
    "### 后验概率最大化的含义\n",
    "假设选择0-1损失函数\n",
    "$$\n",
    "L(Y,f(X))=\\begin{cases}\n",
    "1,Y\\ne f(X)\\\\\n",
    "0,Y=f(X)\n",
    "\\end{cases}\n",
    "$$\n",
    "其中f(X)是分类决策函数，这时，期望风险函数为\n",
    "$$\n",
    "R_{exp}(f)=E[L(Y,f(X))]\n",
    "$$\n",
    "取条件期望\n",
    "$$\n",
    "R_{exp}(f)=E_X\\sum_{k=1}^K[L(c_k,f(X))]P(c_k|X)\n",
    "$$\n",
    "为了使期望风险最小化，只需对X=x逐个最小化，由此得到:\n",
    "$$\n",
    "f(x)=\\operatorname{arg}\\min_y\\sum_{k=1}^K[L(c_k,y)]P(c_k|X=x)\\\\\n",
    "=\\operatorname{arg}\\min_y\\sum_{k=1}^KP(c_k\\ne y|X=x)\\\\\n",
    "=\\operatorname{arg}\\min_y\\sum_{k=1}^K(1-P(c_k=y|X=x))\\\\\n",
    "=\\operatorname{arg}\\max_y\\sum_{k=1}^KP(c_k=y|X=x)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯的参数估计\n",
    "### 极大似然估计\n",
    "先验概率$P(Y=c_j)$的极大似然估计为\n",
    "$$\n",
    "P(Y=c_k)=\\frac{\\sum_{i=1}^NI(y_i=c_k)}{N},\\quad k=1,2,\\cdots,K\n",
    "$$\n",
    "设第j个特征$x^{(j)}$的可能取值集合为${a_{j1},a_{j2},\\cdots,a_{js_j}}$,条件概率$P(X^{(j)=a_{}jl}|Y=c_k)$的极大似然估计为\n",
    "$$\n",
    "P(X^{(j)}|Y=c_k)=\\frac{\\sum_{i=1}^NI(x_i^{(j)}=a_{jl},y_i=c_k)}{\\sum_{i=1}^NI(y_i=c_k)}\\\\j=1,2,\\cdots,n;l=1,2,\\cdots,S_j;k=1,2,\\cdots.K\n",
    "$$\n",
    "### 学习分类算法\n",
    "输入:训练数据$T={(x_1,y_1),(x_2,y_2),\\cdots,(x_n,y_n)}$,其中$x_i=(x_i^{(1)},x_i^{(2)},\\cdots,x_i^{(n)})^T$,$x_i^{(j)}$是第i个样本的第k个特征，$x_i^{(j)}\\in\\{a_{j1},a_{j2},\\cdots,a_{jS_j}\\}$;实例x\n",
    "\n",
    "输出:实例x的分类\n",
    "\n",
    "(1)计算先验概率以及条件概率\n",
    "$$\n",
    "P(Y=c_k)=\\frac{\\sum_{i=1}^NI(y_i=c_k)}{N},\\quad k=1,2,\\cdots,K\\\\\n",
    "P(X^{(j)}|Y=c_k)=\\frac{\\sum_{i=1}^NI(x_i^{(j)}=a_{jl},y_i=c_k)}{\\sum_{i=1}^NI(y_i=c_k)}\\\\j=1,2,\\cdots,n;l=1,2,\\cdots,S_j;k=1,2,\\cdots.K\n",
    "$$\n",
    "(2)对于给定实例$x=(x^{(1)},x^{(2)},\\cdots,x_i^{(n)})^T$计算\n",
    "$$\n",
    "P(Y=c_k)\\prod^n_{j=1}P(X^{(j)}=x^{(j)}|Y=c_k), k=1,2,\\cdots,K\n",
    "$$\n",
    "(3)确定实例x的类\n",
    "$$\n",
    "y=f(x)=\\operatorname{arg}\\max_{c_k}P(Y=c_k)\\prod^n_{j=1}P(X^{(j)}=x^{(j)}|Y=c_k)\n",
    "$$\n",
    "### 贝叶斯估计\n",
    "极大似然法估计会出现概率为0的情况。这时会影响到后验概率的计算结果，会使分类发生偏差，解决这一问题是采用贝叶斯估计具体地，条件概率的贝叶斯估计是\n",
    "$$\n",
    "P_\\lambda(X^{(j)}=a_{jl}|Y=c_k)==\\frac{\\sum_{i=1}^NI(x_i^{(j)}=a_{jl},y_i=c_k)+\\lambda}{\\sum_{i=1}^NI(y_i=c_k)+S_j\\lambda}\n",
    "$$\n",
    "当$\\lambda$=0时，为极大似然估计;当$\\lambda$=0时,成为拉普拉斯平滑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 高斯贝叶斯\n",
    "朴素贝叶斯的计算时默认特征变量是离散的(例如：性别，尺码，年龄)，但对于连续特征(例如：身高，体重)，我们通常使用高斯模型。该模型被称为高斯模型的原因是假定训练样本集T满足高斯分布，即\n",
    "$$\n",
    "T\\sim N(\\mu,\\Sigma)\n",
    "$$\n",
    "## 基本方法\n",
    "高斯贝叶斯方法同样采用朴素贝叶斯方法的条件独立性假设\n",
    "对于Y子类$c_k$,$X^{(j)}\\sim N(\\mu_{jk},\\sigma_{jk})$\n",
    "$$\n",
    "P(X|Y=c_k)=\\prod_{j=1}^n\\frac{1}{\\sqrt{2\\pi}\\sigma_{jk}}exp\\left(-\\frac{(x^{(j)}-\\mu_{jk})^2}{2\\sigma_{jk}^2}\\right)\n",
    "$$\n",
    "其中，$\\mu_{jk}$为子类$c_k$下第j维特征的期望，$\\sigma_{jk}$为子类$c_k$下第j维特征的标准差。\n",
    "在得到连续变量的条件概率计算方法后，进一步的算法与估计与朴素贝叶斯方法相同，就不在赘述。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class GaussianBeyes:\n",
    "    def __init__(self):\n",
    "        self.model=None\n",
    "            \n",
    "    def std(self, X):\n",
    "        avg=sum(X)/float(len(X))\n",
    "        stdev=(math.sqrt(sum([math.pow(x-avg,2) for x in X])/float(len(X))))\n",
    "        return (avg, stdev)\n",
    "    \n",
    "    def  feature_cal(self, X):\n",
    "        return [self.std(i) for i in zip(*X)]#也可以用numpy切片，但是上面没有用ndarray，这里也不默认X为ndarray类型\n",
    "    \n",
    "    def Gaussian(self, x, avg, dev):\n",
    "        return (1/(math.sqrt(2*math.pi)*dev))*math.exp(-(math.pow(x-avg,2)/(2 * math.pow(dev,2))))\n",
    "    \n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        labels=set(y)#标签集合\n",
    "        data={label:[] for label in labels} #每个标签对应一个分类\n",
    "        for x, label in zip(X, y):\n",
    "            data[label].append(x)#X分组\n",
    "        \n",
    "        self.res={\n",
    "            label:self.feature_cal(value) for label,value in data.items()\n",
    "        }#存储每个label对应的特征的平均值与标准差\n",
    "        self.Py={\n",
    "            label:(float(len(data[label]))/float(len(X))) for label in labels\n",
    "        }\n",
    "    #给定一个样本计算概率   \n",
    "    def prob_cal(self, data):\n",
    "        probability={}\n",
    "        for label,value in self.res.items():\n",
    "            probability[label]=self.Py[label]\n",
    "            for i in range(len(value)):\n",
    "                mean,std=value[i]\n",
    "                probability[label]*=self.Gaussian(data[i], mean, std)\n",
    "        return  probability\n",
    "    \n",
    "    def predict(self, X):\n",
    "        label=sorted(self.prob_cal(X).items(), key=lambda x:x[-1])[-1][0]#取概率最大对应的label\n",
    "        return label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array([[60,60],[50,50],[40,40],[40,40],[40,40],[30,30],[60,60],[70,70],[50,50],[90,90],[90,90],[90,90],[170,170],[180,180],[160,160],[170,170]])\n",
    "y=np.array([0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1])\n",
    "bayes=GaussianBeyes()\n",
    "bayes.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes.predict(np.array([120,120]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4.585504651454094e-08, 1: 1.534850361456007e-25}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes.prob_cal(np.array([120,120]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
